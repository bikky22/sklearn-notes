{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine the predictions of several base estimators\n",
    "> * averaging methods (independent estimators : average their predictions)\n",
    "> * boosting methods (sequential estimators : one tries to reduce the bias of the combined estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging meta-estimator #\n",
    "build several instances of a black-box estimator on random subsets of the original training set and then aggregate their individual predictions to form a final prediction\n",
    "\n",
    "> reduce the variance of a base estimator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(),\n",
    "                            max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forests of randomized trees #\n",
    "based on averaging algorithms of decision trees using perturb-and-combine techniques \n",
    "> * RandomForest algorithm \n",
    "> * Extra-Trees method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "Y = [0, 1]\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests ###\n",
    "<b><i>Bootstrap :</i></b>\n",
    "each tree in the ensemble is built from a sample drawn with replacement from the training set.\n",
    "\n",
    "the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extremely Randomized Trees #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=10000, n_features=10, centers=100,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97940879382055857"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,\n",
    "    random_state=0)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99960784313725493"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "    min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,\n",
    "    min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "scores.mean() > 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
